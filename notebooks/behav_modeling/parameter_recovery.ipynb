{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT FINISHED!!! - Parameter recocery\n",
    "\n",
    "This notebook is a test for model fitting. Here we use agents to simulate the task, then we try to recover parameters by fitting the model to the simulated data. Model fitting is through Likelihood estimation.\n",
    "\n",
    "This notebook can also test model comparison tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Imports\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordEpisodeStatistics\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from popy.simulation_tools import *\n",
    "\n",
    "from simulation_helpers import simulate_agent, estimate_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Helpers\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Plotting functions\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "env = gym.make(\"zsombi/monkey-bandit-task-v0\", n_arms=3, max_episode_steps=1_000)\n",
    "\n",
    "# Apply the custom reward wrapper\n",
    "env = ChangeZeroRewardToNegativeOne(env)\n",
    "\n",
    "# initialize the Q-learner agent\n",
    "agent = QLearner(env=env)\n",
    "\n",
    "params_true = {\n",
    "    # initialize the Q-learner agent\n",
    "    'alpha': .1,\n",
    "    'beta': 100,  # rate of exploration (i.e. random actions)\n",
    "    'structure_aware': False\n",
    "}\n",
    "\n",
    "for k, v in params_true.items():\n",
    "    setattr(agent, k, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(best action): 0.60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>best_arm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     action  reward  best_arm\n",
       "0         0       1         1\n",
       "1         0      -1         1\n",
       "2         2      -1         1\n",
       "3         1       1         1\n",
       "4         1       1         1\n",
       "..      ...     ...       ...\n",
       "995       0      -1         2\n",
       "996       0      -1         2\n",
       "997       0      -1         2\n",
       "998       0      -1         2\n",
       "999       0       1         2\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate the agent\n",
    "behavior = simulate_agent(agent)\n",
    "\n",
    "print(f'p(best action): {np.mean(behavior[\"action\"] == behavior[\"best_arm\"]):.2f}')\n",
    "\n",
    "# plot the behavior\n",
    "behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Recover parameters\n",
    "\n",
    "In this section we fit the free parameters of the model and try to recover the true parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       message: Maximum number of function evaluations has been exceeded.\n",
      "       success: False\n",
      "        status: 1\n",
      "           fun: 390.2987798316901\n",
      "             x: [-2.286e-02  1.063e+00]\n",
      "           nit: 150\n",
      "          nfev: 400\n",
      " final_simplex: (array([[-2.286e-02,  1.063e+00],\n",
      "                       [-2.286e-02,  1.063e+00],\n",
      "                       [-2.286e-02,  1.063e+00]]), array([ 3.903e+02,  6.502e+02,  6.502e+02]))\n",
      "\n",
      "MLE: alpha = -0.02 (true value = 0.1)\n",
      "MLE: beta = 1.06 (true value = 100)\n"
     ]
    }
   ],
   "source": [
    "# initialize a naive Q-learner agent\n",
    "agent = QLearner(env=env, structure_aware=True)\n",
    "params_0 = [0.3, 5]\n",
    "\n",
    "result = scipy.optimize.minimize(estimate_ll, params_0, args=(agent, behavior), method=\"Nelder-Mead\") #, options={'maxiter': 1_000})\n",
    "\n",
    "print(result)\n",
    "print(\"\")\n",
    "print(f\"MLE: alpha = {result.x[0]:.2f} (true value = {params_true['alpha']})\")\n",
    "print(f\"MLE: beta = {result.x[1]:.2f} (true value = {params_true['beta']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
