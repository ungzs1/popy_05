{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OFFICE path\n",
      "Inserm drive is not accessible\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:\\ZSOMBI\\OneDrive\\PoPy\")\n",
    "sys.path.append(\"/Users/zsombi/OneDrive/PoPy\")\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from popy.io_tools import *\n",
    "from popy.dim_reduction import *\n",
    "from popy.behavior_data_tools import *\n",
    "from popy.neural_data_tools import time_normalize_session, scale_neural_data, remove_low_fr_neurons, remove_trunctuated_neurons\n",
    "from popy.decoders import *\n",
    "from popy.plotting_tools import *\n",
    "import popy.config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "Session not found: ka_190620_LPFC\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "Session not found: ka_090720_LPFC\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "Session not found: ka_200820_LPFC\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "Session not found: ka_170920_LPFC\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "Session not found: ka_180221_LPFC\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "Session not found: ka_230622_LPFC\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n",
      "Session not found: ka_010922_LPFC\n",
      "adding history of feedback column, but if the data is pooled across sessions, make sure to add the history before pooling data to keep the order of time!\n"
     ]
    }
   ],
   "source": [
    "project_folder = cfg.PROJECT_PATH_LOCAL\n",
    "\n",
    "# sessions info\n",
    "sessions = pd.read_pickle(os.path.join(project_folder, 'data', 'recordings_summary.pickle'))\n",
    "out_path = os.path.join(project_folder, 'data', 'processed', 'rates')\n",
    "\n",
    "neural_data_example = xr.open_dataarray(os.path.join(project_folder, 'data', 'processed', 'rates', 'neural_data_ka_010720.nc'))\n",
    "# Load data\n",
    "# load results\n",
    "\n",
    "session_data = {}\n",
    "\n",
    "for i, row in sessions.iterrows():\n",
    "    if row.monkey != 'ka':\n",
    "        continue\n",
    "    if not row.behav_valid:\n",
    "        continue\n",
    "    if row.interrupted_trials != 0:\n",
    "        continue\n",
    "\n",
    "    monkey, session = row.monkey, row.session\n",
    "    try:\n",
    "        # load behavioral data\n",
    "        behav_data = get_behavior(monkey, session)\n",
    "        behav_data = add_value_function(behav_data)\n",
    "        behav_data = add_switch_info(behav_data)\n",
    "        behav_data = add_phase_info(behav_data, exploration_limit=6, transition_limit=1)\n",
    "        behav_data['value_function'] = behav_data['value_function'].shift(-1)\n",
    "        behav_data['switch'] = behav_data['switch'].shift(-1)\n",
    "        behav_data['phase'] = behav_data['phase'].shift(-1)\n",
    "        behav_data = add_RPE(behav_data)\n",
    "        behav_data = behav_data.dropna()\n",
    "        behav_data['value_function_digit'] = np.digitize(behav_data['value_function'], [0, .25, .5, .75, 1]) - 1\n",
    "        behav_data['RPE_digit'] = np.digitize(behav_data['RPE'], [0, .25, .5, .75, 1]) - 1\n",
    "        #behav_data = drop_time_fields(behav_data)  # remove time fields\n",
    "        behav_data = behav_data.drop(['block_id', 'best_target'], axis=1)  # drop block_id and best_target\n",
    "\n",
    "        # Load neural data\n",
    "        out_path = os.path.join(cfg.PROJECT_PATH_LOCAL, 'data', 'processed', 'rates')\n",
    "        floc = os.path.join(out_path , f'neural_data_{monkey}_{session}.nc')\n",
    "        neural_data = xr.open_dataarray(floc)  #load already preprocessed neual data\n",
    "\n",
    "        # match neural and behavioral data\n",
    "        neural_trials = neural_data.trial_id.values\n",
    "        behav_trials = behav_data.trial_id.values\n",
    "        shared_trials = np.intersect1d(neural_trials, behav_trials)\n",
    "        session_data[session] = {'MCC': {'neural_data': None, \n",
    "                                         'behav_data': None}, \n",
    "                                 'LPFC': {'neural_data': None, \n",
    "                                          'behav_data': None}}\n",
    "        for area in ['MCC', 'LPFC']:\n",
    "            neural_data_area = neural_data[neural_data.area == area]  # select only PFC\n",
    "            session_data[session][area]['neural_data'] = neural_data_area[:, neural_data_area.trial_id.isin(shared_trials)]\n",
    "            session_data[session][area]['behav_data'] = behav_data[behav_data.trial_id.isin(shared_trials)]\n",
    "\n",
    "    except:\n",
    "        print(f'Session not found: {monkey}_{session}_{area}')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "050620 MCC\n",
      "050620 LPFC\n",
      "100620 MCC\n",
      "100620 LPFC\n",
      "010720 MCC\n",
      "010720 LPFC\n",
      "150720 MCC\n",
      "150720 LPFC\n",
      "230720 MCC\n",
      "230720 LPFC\n",
      "270720 MCC\n",
      "270720 LPFC\n",
      "300720 MCC\n",
      "300720 LPFC\n",
      "100820 MCC\n",
      "100820 LPFC\n",
      "120820 MCC\n",
      "120820 LPFC\n",
      "240820 MCC\n",
      "240820 LPFC\n",
      "310820 MCC\n",
      "310820 LPFC\n",
      "100920 MCC\n",
      "100920 LPFC\n",
      "011020 MCC\n",
      "011020 LPFC\n",
      "221020 MCC\n",
      "221020 LPFC\n",
      "281020 MCC\n",
      "281020 LPFC\n",
      "150221 MCC\n",
      "150221 LPFC\n",
      "040321 MCC\n",
      "040321 LPFC\n",
      "110321 MCC\n",
      "110321 LPFC\n",
      "180321 MCC\n",
      "180321 LPFC\n",
      "120821 MCC\n",
      "120821 LPFC\n",
      "190821 MCC\n",
      "190821 LPFC\n",
      "290921 MCC\n",
      "290921 LPFC\n",
      "030322 MCC\n",
      "030322 LPFC\n",
      "070322 MCC\n",
      "070322 LPFC\n",
      "210322 MCC\n",
      "210322 LPFC\n",
      "280322 MCC\n",
      "280322 LPFC\n",
      "050422 MCC\n",
      "050422 LPFC\n",
      "130422 MCC\n",
      "130422 LPFC\n",
      "200422 MCC\n",
      "200422 LPFC\n",
      "250422 MCC\n",
      "250422 LPFC\n",
      "030522 MCC\n",
      "030522 LPFC\n",
      "020622 MCC\n",
      "020622 LPFC\n",
      "080622 MCC\n",
      "080622 LPFC\n",
      "130622 MCC\n",
      "130622 LPFC\n",
      "200622 MCC\n",
      "200622 LPFC\n",
      "280622 MCC\n",
      "280622 LPFC\n",
      "300622 MCC\n",
      "300622 LPFC\n",
      "070722 MCC\n",
      "070722 LPFC\n",
      "080822 MCC\n",
      "080822 LPFC\n",
      "300822 MCC\n",
      "300822 LPFC\n",
      "060922 MCC\n",
      "060922 LPFC\n"
     ]
    }
   ],
   "source": [
    "## Generate PCA\n",
    "monkey = 'ka'\n",
    "for session, data_all in session_data.items():\n",
    "    for area, data in data_all.items():\n",
    "        print(session, area)\n",
    "        neural_data_area = data['neural_data']\n",
    "        if neural_data_area.shape[0] <= 4:\n",
    "            continue\n",
    "        behav_data = data['behav_data']\n",
    "        #modes = ['full', 'mean', 'full_cut', 'mean_cut', 'behav']\n",
    "        pca_of_interest = 'full'\n",
    "        condition_of_interest = 'target'\n",
    "\n",
    "        # fit PCA\n",
    "        pca = fit_model(behav_data, neural_data_area, mode=pca_of_interest,\n",
    "                        behav_condition=condition_of_interest)\n",
    "\n",
    "        PCA_data = neural_data_area.copy(data=pca.transform(neural_data_area.T).T)\n",
    "\n",
    "        # prepare data for plotting\n",
    "        # df to collect PCA trajectories for plottingresults per condition\n",
    "        T_all = pd.DataFrame(columns=['feedback', 'RPE_digit', 'value_function_digit', 'switch', 'target'],\n",
    "                                index=[area])\n",
    "\n",
    "        n_components = 4  # number of components to use for plotting\n",
    "        for condition in T_all.columns:\n",
    "            T_full, labels = build_dataset(PCA_data, behav_data, \n",
    "                                        starts_on='fb-1', ends_on='fb+2',\n",
    "                                        target_name=condition)\n",
    "\n",
    "            T_current = {}\n",
    "            # get mean trial activity per condition\n",
    "            for label in np.unique(labels):\n",
    "                T_temp = np.mean(T_full[labels == label], axis=0)  # mean activity per condition\n",
    "                #T_temp = T_temp - T_mean  # subtract full mean activity\n",
    "                T_current[label] = T_temp[:n_components, :]  # save only the first n_components\n",
    "            T_all[condition][area] = T_current\n",
    "\n",
    "        # plot\n",
    "        title = f'Representation of conditions in PC space, {monkey} {session} {area} {pca_of_interest}'\n",
    "        savedir = os.path.join(project_folder, 'figs', 'pca', 'all', f'{monkey}_{session}_{area}_pca_full.png')\n",
    "        show_PCA_trajectories(neural_data, T_all, pca.explained_variance_ratio_, n_components=n_components, \n",
    "        title=title, savedir=savedir, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "summary.pdf created at C:\\ZSOMBI\\OneDrive\\PoPy\\figs\\pca\\summary.pdf\n"
     ]
    }
   ],
   "source": [
    "## Merge plots to one big pdf\n",
    "# merge pngs in the location to one main pdf\n",
    "import os\n",
    "from PIL import Image\n",
    "#import img2pdf\n",
    "from pypdf import PdfMerger\n",
    "\n",
    "\n",
    "def merge_pdfs(path, output_name):\n",
    "    pdfs = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\"_pca_full.pdf\"):\n",
    "            pdfs.append(os.path.join(path, file))\n",
    "\n",
    "    merger = PdfMerger()\n",
    "\n",
    "    # sort by name\n",
    "    pdfs.sort()\n",
    "\n",
    "    # change the order from 1,2,3,4... to 2,1,4,3...\n",
    "    pdfs = [item for sublist in zip(pdfs[1::2], pdfs[::2]) for item in sublist]\n",
    "    print(pdfs)\n",
    "\n",
    "    for pdf in pdfs:\n",
    "        merger.append(pdf)\n",
    "\n",
    "    merger.write(output_name)\n",
    "    merger.close()\n",
    "\n",
    "path = os.path.join(project_folder, 'figs', 'pca', 'all')\n",
    "output_name = os.path.join(project_folder, 'figs', 'pca', 'summary.pdf')\n",
    "merge_pdfs(path, output_name)\n",
    "\n",
    "print(\"summary.pdf created at \" + output_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbri3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
